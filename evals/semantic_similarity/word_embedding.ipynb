{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports and Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These concept sets are available: ['anthropic', 'adjectives']\n"
     ]
    }
   ],
   "source": [
    "# Load concepts\n",
    "with open('concepts.json') as f:\n",
    "    concepts = json.load(f)\n",
    "\n",
    "# Print first 5 adjectives\n",
    "print(f'These concept sets are available: {list(concepts.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_name = 'adjectives'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# # # Initialize SentenceTransformer model\n",
    "# model_name = 'nomic'\n",
    "# model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate embeddings\n",
    "# queries = concepts['adjectives']\n",
    "# query_embeddings = model.encode(queries)\n",
    "# print(f'shape of query_embeddings: {query_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NV-embed-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModel\n",
    "\n",
    "# # load model with tokenizer\n",
    "# model_name = 'nv-embed-v2'\n",
    "# model = AutoModel.from_pretrained('nvidia/NV-Embed-v2', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# # Each query needs to be accompanied by an corresponding instruction describing the task.\n",
    "# task_name_to_instruct = {\"example\": \"Given a query word, retrieve semantically similar words.\",}\n",
    "\n",
    "# query_prefix = \"Instruct: \"+task_name_to_instruct[\"example\"]+\"\\nQuery: \"\n",
    "# queries =\n",
    "\n",
    "# # No instruction needed for retrieval passages\n",
    "# passage_prefix = \"\"\n",
    "# passages = [\n",
    "#     \"Since you're reading this, you are probably someone from a judo background or someone who is just wondering how judo techniques can be applied under wrestling rules. So without further ado, let's get to the question. Are Judo throws allowed in wrestling? Yes, judo throws are allowed in freestyle and folkstyle wrestling. You only need to be careful to follow the slam rules when executing judo throws. In wrestling, a slam is lifting and returning an opponent to the mat with unnecessary force.\",\n",
    "#     \"Below are the basic steps to becoming a radiologic technologist in Michigan:Earn a high school diploma. As with most careers in health care, a high school education is the first step to finding entry-level employment. Taking classes in math and science, such as anatomy, biology, chemistry, physiology, and physics, can help prepare students for their college studies and future careers.Earn an associate degree. Entry-level radiologic positions typically require at least an Associate of Applied Science. Before enrolling in one of these degree programs, students should make sure it has been properly accredited by the Joint Review Committee on Education in Radiologic Technology (JRCERT).Get licensed or certified in the state of Michigan.\"\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# # get the embeddings\n",
    "# max_length = 32768\n",
    "# query_embeddings = model.encode(queries, instruction=query_prefix, max_length=max_length)\n",
    "# passage_embeddings = model.encode(passages, instruction=passage_prefix, max_length=max_length)\n",
    "\n",
    "# # normalize embeddings\n",
    "# query_embeddings = F.normalize(query_embeddings, p=2, dim=1)\n",
    "# passage_embeddings = F.normalize(passage_embeddings, p=2, dim=1)\n",
    "\n",
    "# # get the embeddings with DataLoader (spliting the datasets into multiple mini-batches)\n",
    "# # batch_size=2\n",
    "# # query_embeddings = model._do_encode(queries, batch_size=batch_size, instruction=query_prefix, max_length=max_length, num_workers=32, return_numpy=True)\n",
    "# # passage_embeddings = model._do_encode(passages, batch_size=batch_size, instruction=passage_prefix, max_length=max_length, num_workers=32, return_numpy=True)\n",
    "\n",
    "# scores = (query_embeddings @ passage_embeddings.T) * 100\n",
    "# print(scores.tolist())\n",
    "# # [[87.42693328857422, 0.46283677220344543], [0.965264618396759, 86.03721618652344]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma-2-9B based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Load the model, optionally in float16 precision for faster inference\n",
    "embedding_name = 'BAAI/bge-multilingual-gemma2'\n",
    "model = SentenceTransformer(embedding_name, model_kwargs={\"torch_dtype\": torch.float16, 'device_map': 'cuda'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a prompt given an instruction\n",
    "instruction = 'Given a web search query, retrieve relevant passages that answer the query.'\n",
    "# instruction = 'Given a query word, retrieve semantically similar target words.'\n",
    "prompt = f'<instruct>{instruction}\\n<query>'\n",
    "\n",
    "# Compute the query and document embeddings\n",
    "concept_embeddings = model.encode(concepts[concept_name], prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity fn: cosine\n",
      "tensor([[1.0000, 0.3770, 0.3789,  ..., 0.2612, 0.2250, 0.3523],\n",
      "        [0.3770, 1.0000, 0.4480,  ..., 0.3066, 0.3049, 0.2629],\n",
      "        [0.3789, 0.4480, 1.0010,  ..., 0.2615, 0.2410, 0.2573],\n",
      "        ...,\n",
      "        [0.2612, 0.3066, 0.2615,  ..., 0.9990, 0.4751, 0.3674],\n",
      "        [0.2250, 0.3049, 0.2410,  ..., 0.4751, 0.9995, 0.4421],\n",
      "        [0.3523, 0.2629, 0.2573,  ..., 0.3674, 0.4421, 0.9995]],\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Compute the cosine similarity between the query and document embeddings\n",
    "fn_name = model.similarity_fn_name\n",
    "print(f'similarity fn: {fn_name}')\n",
    "\n",
    "similarities = model.similarity(concept_embeddings, concept_embeddings)\n",
    "print(similarities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_sim = pd.DataFrame(similarities, index=concepts[concept_name], columns=concepts[concept_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warm           0.999512\n",
       "hot            0.533203\n",
       "cold           0.507324\n",
       "calm           0.468994\n",
       "cool           0.461670\n",
       "weak           0.444092\n",
       "cozy           0.429199\n",
       "wet            0.427979\n",
       "wary           0.426758\n",
       "warlike        0.425049\n",
       "wide           0.425049\n",
       "soft           0.422119\n",
       "strong         0.420166\n",
       "wild           0.415771\n",
       "firm           0.412842\n",
       "sweet          0.405518\n",
       "round          0.397949\n",
       "friendly       0.396240\n",
       "happy          0.395752\n",
       "rich           0.394287\n",
       "fresh          0.393066\n",
       "wise           0.392578\n",
       "dark           0.391113\n",
       "bright         0.389648\n",
       "familiar       0.389404\n",
       "smart          0.389160\n",
       "wealthy        0.387695\n",
       "smooth         0.384033\n",
       "sharp          0.383789\n",
       "normal         0.383057\n",
       "comfortable    0.382812\n",
       "romantic       0.382812\n",
       "dry            0.381348\n",
       "spicy          0.376709\n",
       "brown          0.375488\n",
       "safe           0.374023\n",
       "narrow         0.373535\n",
       "charming       0.370117\n",
       "lovely         0.370117\n",
       "brave          0.369385\n",
       "tight          0.369141\n",
       "damp           0.368896\n",
       "cute           0.367188\n",
       "aware          0.366943\n",
       "mature         0.366455\n",
       "stormy         0.365479\n",
       "nice           0.364746\n",
       "golden         0.364258\n",
       "modern         0.364014\n",
       "gentle         0.363525\n",
       "poor           0.362549\n",
       "healthy        0.362305\n",
       "keen           0.361572\n",
       "windy          0.361328\n",
       "deep           0.361084\n",
       "hard           0.360840\n",
       "angry          0.360107\n",
       "bold           0.359131\n",
       "clean          0.358398\n",
       "frozen         0.358154\n",
       "tender         0.357666\n",
       "quiet          0.357666\n",
       "grand          0.356689\n",
       "mean           0.356445\n",
       "organic        0.355225\n",
       "early          0.354248\n",
       "near           0.354248\n",
       "internal       0.353271\n",
       "quaint         0.353271\n",
       "loud           0.353027\n",
       "sour           0.352539\n",
       "weary          0.351807\n",
       "dynamic        0.351318\n",
       "pleasant       0.351318\n",
       "good           0.351074\n",
       "fine           0.350830\n",
       "whole          0.350586\n",
       "white          0.350586\n",
       "coarse         0.350586\n",
       "caring         0.350098\n",
       "animated       0.348145\n",
       "thick          0.348145\n",
       "heavy          0.348145\n",
       "stiff          0.346680\n",
       "large          0.346680\n",
       "thirsty        0.345459\n",
       "watery         0.345215\n",
       "great          0.345215\n",
       "open           0.344482\n",
       "hungry         0.344482\n",
       "clear          0.344238\n",
       "neat           0.344238\n",
       "harsh          0.343994\n",
       "lean           0.343750\n",
       "conscious      0.343750\n",
       "tall           0.343506\n",
       "mixed          0.343506\n",
       "dirty          0.343262\n",
       "careful        0.343018\n",
       "fair           0.342529\n",
       "Name: warm, dtype: float16"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'warm'\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "df_sim[word].sort_values(ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "output = {\n",
    "    'concepts': {concept_name: concepts[concept_name]},\n",
    "    'similarities': similarities,\n",
    "    'config': {\n",
    "        'concept_name': concept_name,\n",
    "        'embedding_name': embedding_name,\n",
    "        'fn_name': fn_name,\n",
    "    }\n",
    "}\n",
    "\n",
    "fname = f'{concept_name}_{embedding_name}_{fn_name}.pkl'\n",
    "fname = fname.replace('/', '-')\n",
    "with open(fname, 'wb') as f:\n",
    "    pkl.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['adjectives'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['concepts'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
