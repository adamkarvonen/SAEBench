{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any, Optional\n",
    "\n",
    "import evals.core.main as core\n",
    "import evals.scr_and_tpp.main as scr_and_tpp\n",
    "import evals.sparse_probing.main as sparse_probing\n",
    "import sae_bench_utils.general_utils as general_utils\n",
    "import custom_saes.custom_sae_config as custom_sae_config\n",
    "import custom_saes.vanilla_sae as vanilla_sae\n",
    "from sae_bench_utils.sae_selection_utils import get_saes_from_regex\n",
    "import custom_saes.run_all_evals_custom_saes as run_all_evals_custom_saes\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "output_folders = {\n",
    "    \"absorption\": \"eval_results/absorption\",\n",
    "    \"autointerp\": \"eval_results/autointerp\",\n",
    "    \"core\": \"eval_results/core\",\n",
    "    \"scr\": \"eval_results/scr\",\n",
    "    \"tpp\": \"eval_results/tpp\",\n",
    "    \"sparse_probing\": \"eval_results/sparse_probing\",\n",
    "    \"unlearning\": \"eval_results/unlearning\",\n",
    "}\n",
    "\n",
    "# Note: Unlearning is not recommended for models with < 2B parameters and we recommend an instruct tuned model\n",
    "# Unlearning will also require requesting permission for the WMDP dataset (see unlearning/README.md)\n",
    "# Absorption not recommended for models < 2B parameters\n",
    "# asyncio doesn't like notebooks, so autointerp must be ran using a python script\n",
    "\n",
    "# Select your eval types here. \n",
    "eval_types = [\n",
    "    \"absorption\",\n",
    "    # \"autointerp\",\n",
    "    \"core\",\n",
    "    \"scr\",\n",
    "    \"tpp\",\n",
    "    \"sparse_probing\",\n",
    "    # \"unlearning\",\n",
    "]\n",
    "\n",
    "if \"autointerp\" in eval_types:\n",
    "    raise ValueError(\"autointerp must be ran using a python script\")\n",
    "\n",
    "device = general_utils.setup_environment()\n",
    "\n",
    "model_name = \"gemma-2-2b\"\n",
    "llm_batch_size = 32\n",
    "dtype = \"bfloat16\"\n",
    "\n",
    "\n",
    "# If evaluating multiple SAEs on the same layer, set save_activations to True\n",
    "# This will require at least 100GB of disk space\n",
    "save_activations = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell loads your custom SAEs. If you just want to use existing SAE Lens SAEs, comment it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "repo_id = \"canrager/lm_sae\"\n",
    "baseline_filename = \"pythia70m_sweep_standard_ctx128_0712/resid_post_layer_4/trainer_8/ae.pt\"\n",
    "hook_layer = 4\n",
    "hook_name = f\"blocks.{hook_layer}.hook_resid_post\"\n",
    "\n",
    "sae = vanilla_sae.load_vanilla_sae(repo_id, baseline_filename, hook_layer)\n",
    "sae = sae.to(device, dtype=general_utils.str_to_dtype(dtype))\n",
    "\n",
    "print(f\"sae dtype: {sae.dtype}, device: {sae.device}\")\n",
    "\n",
    "d_sae, d_in = sae.W_dec.data.shape\n",
    "\n",
    "assert d_sae >= d_in\n",
    "\n",
    "print(f\"d_in: {d_in}, d_sae: {d_sae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our sae object we need to have a CustomSAEConfig. This contains some information which is used by the evals (hook_name, hook_layer, model_name, d_sae, etc). In addition, it contains information that is used by our plotting functions, like number of training tokens and architecture. For example, we should have the sae.cfg.architecture defined if we want to plot multiple SAE architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_in' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sae\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m custom_sae_config\u001b[38;5;241m.\u001b[39mCustomSAEConfig(\n\u001b[0;32m----> 2\u001b[0m     model_name, d_in\u001b[38;5;241m=\u001b[39m\u001b[43md_in\u001b[49m, d_sae\u001b[38;5;241m=\u001b[39md_sae, hook_name\u001b[38;5;241m=\u001b[39mhook_name, hook_layer\u001b[38;5;241m=\u001b[39mhook_layer\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Core evals require us to specify the dtype. This must be a string that can be converted to a torch dtype using general_utils.str_to_dtype.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m sae\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m dtype\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd_in' is not defined"
     ]
    }
   ],
   "source": [
    "sae.cfg = custom_sae_config.CustomSAEConfig(\n",
    "    model_name, d_in=d_in, d_sae=d_sae, hook_name=hook_name, hook_layer=hook_layer\n",
    ")\n",
    "\n",
    "# Core evals require us to specify the dtype. This must be a string that can be converted to a torch dtype using general_utils.str_to_dtype.\n",
    "sae.cfg.dtype = dtype\n",
    "\n",
    "\n",
    "# The following contains our current defined SAE types and the shapes to plot for each. Add your custom SAE as new_sae_key\n",
    "new_sae_key = \"vanilla\"\n",
    "trainer_markers = {\n",
    "    \"standard\": \"o\",\n",
    "    \"jumprelu\": \"X\",\n",
    "    \"topk\": \"^\",\n",
    "    \"p_anneal\": \"*\",\n",
    "    \"gated\": \"d\",\n",
    "    new_sae_key: \"s\",  # New SAE\n",
    "}\n",
    "\n",
    "sae.cfg.architecture = new_sae_key\n",
    "sae.cfg.training_tokens = 200_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`selected_saes` is a list of tuples of (unique_sae_id, sae object) OR (sae lens release, sae lens id). If it is a list of custom sae objects, then memory size will increase with the length of the list. This is especially important if the SAEs are large. If memory is a concern, I recommend calling the `run_eval()` function multiple times with lists of length 1, each list containing a new sae object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the custom_sae_id should be unique, as it is used for the intermediate results and final results file names\n",
    "\n",
    "unique_custom_sae_id = baseline_filename.replace(\"/\", \"_\").replace(\".\", \"_\")\n",
    "print(f\"sae_id: {unique_custom_sae_id}\")\n",
    "\n",
    "# list of tuple of (sae_id, sae object)\n",
    "custom_saes = [(unique_custom_sae_id, sae)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select your baseline SAEs here. Refer to `sae_regex_selection.ipynb` for more regex patterns. We are going to get a topk SAE from the same layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:00<00:00, 90387.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_saes: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m baseline_saes \u001b[38;5;241m=\u001b[39m get_saes_from_regex(sae_regex_pattern, sae_block_pattern)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline_saes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_saes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m baseline_sae_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbaseline_saes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_saes[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline_sae_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_sae_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m baseline_saes\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# sae_regex_pattern = r\"(sae_bench_pythia70m_sweep_topk_ctx128_0730).*\"\n",
    "# sae_block_pattern = r\".*blocks\\.([4])\\.hook_resid_post__trainer_(8)$\"\n",
    "# sae_regex_pattern = r\"gemma-2-2b_layer_5_additivity.*\"\n",
    "# sae_block_pattern = r\".*_trainer_0\"\n",
    "\n",
    "baseline_saes = get_saes_from_regex(sae_regex_pattern, sae_block_pattern)\n",
    "print(f\"baseline_saes: {baseline_saes}\")\n",
    "baseline_sae_id = f\"{baseline_saes[0][0]}_{baseline_saes[0][1]}\".replace(\".\", \"_\")\n",
    "print(f\"baseline_sae_id: {baseline_sae_id}\")\n",
    "\n",
    "baseline_saes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run time for the next 2 functions is approximately 2 minutes on an RTX 3090."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We typically run with n_eval_sparsity_variance_batches=2000, but I have reduced it here for a faster run\n",
    "\n",
    "_ = core.multiple_evals(\n",
    "    selected_saes=selected_saes,\n",
    "    n_eval_reconstruction_batches=200,\n",
    "    n_eval_sparsity_variance_batches=200,\n",
    "    eval_batch_size_prompts=32,\n",
    "    compute_featurewise_density_statistics=False,\n",
    "    compute_featurewise_weight_based_metrics=False,\n",
    "    exclude_special_tokens_from_reconstruction=True,\n",
    "    dataset=\"Skylion007/openwebtext\",\n",
    "    context_size=128,\n",
    "    output_folder=\"eval_results/core\",\n",
    "    verbose=True,\n",
    "    dtype=dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do a subset of the sparse probing datasets here for shorter runtime\n",
    "dataset_names = [\"LabHC/bias_in_bios_class_set1\"]\n",
    "\n",
    "# TODO: Add a verbose flag\n",
    "\n",
    "_ = sparse_probing.run_eval(\n",
    "    sparse_probing.SparseProbingEvalConfig(\n",
    "        model_name=model_name,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        llm_batch_size=llm_batch_size,\n",
    "        llm_dtype=dtype,\n",
    "        dataset_names=dataset_names,\n",
    "    ),\n",
    "    selected_saes,\n",
    "    device,\n",
    "    \"eval_results/sparse_probing\",\n",
    "    force_rerun=False,\n",
    "    clean_up_activations=True,\n",
    "    save_activations=save_activations,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will run all evals on the full datasets. By default, we don't do this as it's pretty time consuming (~1 hour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = run_all_evals_custom_saes.run_evals(\n",
    "#     model_name,\n",
    "#     selected_saes,\n",
    "#     llm_batch_size,\n",
    "#     dtype,\n",
    "#     device,\n",
    "#     eval_types,\n",
    "#     api_key,\n",
    "#     force_rerun=False,\n",
    "#     save_activations=save_activations,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from typing import Optional\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sae_bench_utils.graphing_utils as graphing_utils\n",
    "\n",
    "from sae_bench_utils.sae_selection_utils import select_saes_multiple_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"./eval_results/absorption\"\n",
    "\n",
    "core_results_path = \"./eval_results/core\"\n",
    "image_path = \"./images\"\n",
    "\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/u/can/SAEBench/custom_saes/topk_sae.py:110: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt_params = t.load(path_to_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config: {'trainer': {'trainer_class': 'TrainerTopKAdditivity', 'dict_class': 'AutoEncoderTopK', 'lr': 0.000282842712474619, 'steps': 48828, 'seed': 0, 'activation_dim': 2304, 'dict_size': 8192, 'k': 20, 'auxk_alpha': 0.03125, 'additivity_coeff': 0.0, 'intersection_coeff': 0.0, 'device': 'cuda:0', 'layer': 4, 'lm_name': 'google/gemma-2-2b', 'wandb_name': 'TopKTrainer_Additivity-google/gemma-2-2b-resid_post_layer_4-add_coeff-0.0-inters_coeff-0.0', 'submodule_name': 'resid_post_layer_4'}, 'buffer': {'d_submodule': 2304, 'io': 'out', 'n_ctxs': 8192, 'ctx_len': 128, 'refresh_batch_size': 32, 'out_batch_size': 2048, 'device': 'cuda:0'}}\n",
      "Original keys in state_dict: odict_keys(['b_dec', 'encoder.weight', 'encoder.bias', 'decoder.weight'])\n",
      "Renamed keys in state_dict: dict_keys(['b_dec', 'W_enc', 'b_enc', 'W_dec'])\n",
      "Loaded config: {'trainer': {'trainer_class': 'TrainerTopKAdditivity', 'dict_class': 'AutoEncoderTopK', 'lr': 0.000282842712474619, 'steps': 48828, 'seed': 0, 'activation_dim': 2304, 'dict_size': 8192, 'k': 20, 'auxk_alpha': 0.03125, 'additivity_coeff': 0.0, 'intersection_coeff': 1.0, 'device': 'cuda:0', 'layer': 4, 'lm_name': 'google/gemma-2-2b', 'wandb_name': 'TopKTrainer_Additivity-google/gemma-2-2b-resid_post_layer_4-add_coeff-0.0-inters_coeff-1.0', 'submodule_name': 'resid_post_layer_4'}, 'buffer': {'d_submodule': 2304, 'io': 'out', 'n_ctxs': 8192, 'ctx_len': 128, 'refresh_batch_size': 32, 'out_batch_size': 2048, 'device': 'cuda:0'}}\n",
      "Original keys in state_dict: odict_keys(['b_dec', 'encoder.weight', 'encoder.bias', 'decoder.weight'])\n",
      "Renamed keys in state_dict: dict_keys(['b_dec', 'W_enc', 'b_enc', 'W_dec'])\n",
      "Loaded config: {'trainer': {'trainer_class': 'TrainerTopKAdditivity', 'dict_class': 'AutoEncoderTopK', 'lr': 0.000282842712474619, 'steps': 48828, 'seed': 0, 'activation_dim': 2304, 'dict_size': 8192, 'k': 20, 'auxk_alpha': 0.03125, 'additivity_coeff': 1.0, 'intersection_coeff': 0.0, 'device': 'cuda:0', 'layer': 4, 'lm_name': 'google/gemma-2-2b', 'wandb_name': 'TopKTrainer_Additivity-google/gemma-2-2b-resid_post_layer_4-add_coeff-1.0-inters_coeff-0.0', 'submodule_name': 'resid_post_layer_4'}, 'buffer': {'d_submodule': 2304, 'io': 'out', 'n_ctxs': 8192, 'ctx_len': 128, 'refresh_batch_size': 32, 'out_batch_size': 2048, 'device': 'cuda:0'}}\n",
      "Original keys in state_dict: odict_keys(['b_dec', 'encoder.weight', 'encoder.bias', 'decoder.weight'])\n",
      "Renamed keys in state_dict: dict_keys(['b_dec', 'W_enc', 'b_enc', 'W_dec'])\n",
      "Loaded config: {'trainer': {'trainer_class': 'TrainerTopKAdditivity', 'dict_class': 'AutoEncoderTopK', 'lr': 0.000282842712474619, 'steps': 48828, 'seed': 0, 'activation_dim': 2304, 'dict_size': 8192, 'k': 20, 'auxk_alpha': 0.03125, 'additivity_coeff': 1.0, 'intersection_coeff': 1.0, 'device': 'cuda:0', 'layer': 4, 'lm_name': 'google/gemma-2-2b', 'wandb_name': 'TopKTrainer_Additivity-google/gemma-2-2b-resid_post_layer_4-add_coeff-1.0-inters_coeff-1.0', 'submodule_name': 'resid_post_layer_4'}, 'buffer': {'d_submodule': 2304, 'io': 'out', 'n_ctxs': 8192, 'ctx_len': 128, 'refresh_batch_size': 32, 'out_batch_size': 2048, 'device': 'cuda:0'}}\n",
      "Original keys in state_dict: odict_keys(['b_dec', 'encoder.weight', 'encoder.bias', 'decoder.weight'])\n",
      "Renamed keys in state_dict: dict_keys(['b_dec', 'W_enc', 'b_enc', 'W_dec'])\n"
     ]
    }
   ],
   "source": [
    "from custom_saes.topk_sae import load_topk_sae\n",
    "\n",
    "repo_id = \"webcrg/additivity\"\n",
    "hook_layer = 5\n",
    "\n",
    "selected_saes = []\n",
    "for trainer_id in range(4):\n",
    "    trainer_path = f\"gemma-2-2b_layer-4_width-2pow13_date-1204/trainer_{trainer_id}\"\n",
    "    filename = os.path.join(trainer_path, \"ae.pt\")\n",
    "    config_filename = os.path.join(trainer_path, \"config.json\")\n",
    "    sae = load_topk_sae(repo_id, filename, config_filename, hook_layer)\n",
    "    # sae = identity_sae.IdentitySAE(model_name, d_model, hook_layer, context_size=128)\n",
    "    selected_saes.append((f\"{model_name}_layer_{hook_layer}_additivity_trainer_{trainer_id}\", sae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sae_ids = []\n",
    "\n",
    "for sae_id, sae in selected_saes:\n",
    "    custom_sae_ids.append((sae_id, \"custom_sae\"))\n",
    "\n",
    "# sae_lens_ids = []\n",
    "\n",
    "# for sae_id, sae_release in baseline_saes:\n",
    "#     sae_lens_ids.append((sae_id, sae_release))\n",
    "\n",
    "graphing_sae_ids = custom_sae_ids # + sae_lens_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can view the raw results, and we see that both SAEs significantly outperform the residual stream baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gemma-2-2b_layer_5_additivity_trainer_0', 'custom_sae'),\n",
       " ('gemma-2-2b_layer_5_additivity_trainer_1', 'custom_sae'),\n",
       " ('gemma-2-2b_layer_5_additivity_trainer_2', 'custom_sae'),\n",
       " ('gemma-2-2b_layer_5_additivity_trainer_3', 'custom_sae')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphing_sae_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['gemma-2-2b_layer_5_additivity_trainer_0_custom_sae', 'gemma-2-2b_layer_5_additivity_trainer_1_custom_sae', 'gemma-2-2b_layer_5_additivity_trainer_2_custom_sae', 'gemma-2-2b_layer_5_additivity_trainer_3_custom_sae'])\n"
     ]
    }
   ],
   "source": [
    "raw_results_dict = graphing_utils.get_results_dict(graphing_sae_ids, eval_path, core_results_path)\n",
    "\n",
    "print(raw_results_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sae_id = f\"{custom_sae_ids[0][0]}_{custom_sae_ids[0][1]}\".replace(\".\", \"_\")\n",
    "# baseline_sae_id = f\"{sae_lens_ids[0][0]}_{sae_lens_ids[0][1]}\"\n",
    "\n",
    "\n",
    "# baseline_filename = f\"{sae_lens_ids[0][0]}_{sae_lens_ids[0][1]}_eval_results.json\".replace(\"/\", \"_\")\n",
    "# baseline_filepath = os.path.join(eval_path, baseline_filename)\n",
    "\n",
    "# with open(baseline_filepath, \"r\") as f:\n",
    "#     baseline_sae_eval_results = json.load(f)\n",
    "\n",
    "custom_filename = f\"{custom_sae_ids[0][0]}_{custom_sae_ids[0][1]}_eval_results.json\".replace(\"/\", \"_\")\n",
    "custom_filepath = os.path.join(eval_path, custom_filename)\n",
    "\n",
    "with open(custom_filepath, \"r\") as f:\n",
    "    custom_sae_eval_results = json.load(f)\n",
    "\n",
    "# k = 1\n",
    "\n",
    "# print(baseline_sae_eval_results.keys())\n",
    "\n",
    "# print(f\"Baseline SAE top {k} accuracy was:\", baseline_sae_eval_results[\"eval_result_metrics\"]['sae'][f'sae_top_{k}_test_accuracy'])\n",
    "# print(f\"Custom SAE top {k} accuracy was:\", custom_sae_eval_results[\"eval_result_metrics\"]['sae'][f'sae_top_{k}_test_accuracy'])\n",
    "# print(f\"LLM top {k} accuracy was:\" , baseline_sae_eval_results[\"eval_result_metrics\"]['llm'][f'llm_top_{k}_test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the metrics, plotting L0 vs Custom Metric or L0 vs Loss Recovered vs Custom metric. We can have different shapes for the SAE type or dictionary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_markers = {\n",
    "    \"standard\": \"o\",\n",
    "    \"jumprelu\": \"X\",\n",
    "    \"topk\": \"^\",\n",
    "    \"p_anneal\": \"*\",\n",
    "    \"gated\": \"d\",\n",
    "    # new_sae_key: \"s\",  # New SAE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./images/absorption'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gemma-2-2b_layer_5_additivity_trainer_0_custom_sae': {'mean_absorption_score': 0.1354606266610463, 'mean_num_split_features': 2.0, 'eval_config': {'model_name': 'gemma-2-2b', 'random_seed': 42, 'f1_jump_threshold': 0.03, 'max_k_value': 10, 'prompt_template': '{word} has the first letter:', 'prompt_token_pos': -6, 'llm_batch_size': 32, 'llm_dtype': 'bfloat16', 'k_sparse_probe_l1_decay': 0.01, 'k_sparse_probe_batch_size': 4096, 'k_sparse_probe_num_epochs': 50}, 'sae_class': '', 'd_sae': 8000, 'train_tokens': 1e-06, 'l0': 19.999998092651367, 'frac_recovered': 0.8585526315789473}, 'gemma-2-2b_layer_5_additivity_trainer_1_custom_sae': {'mean_absorption_score': 0.14887349997275068, 'mean_num_split_features': 2.0, 'eval_config': {'model_name': 'gemma-2-2b', 'random_seed': 42, 'f1_jump_threshold': 0.03, 'max_k_value': 10, 'prompt_template': '{word} has the first letter:', 'prompt_token_pos': -6, 'llm_batch_size': 32, 'llm_dtype': 'bfloat16', 'k_sparse_probe_l1_decay': 0.01, 'k_sparse_probe_batch_size': 4096, 'k_sparse_probe_num_epochs': 50}, 'sae_class': '', 'd_sae': 8000, 'train_tokens': 1e-06, 'l0': 19.999977111816406, 'frac_recovered': 0.8585526315789473}, 'gemma-2-2b_layer_5_additivity_trainer_2_custom_sae': {'mean_absorption_score': 0.28336021725316013, 'mean_num_split_features': 2.576923076923077, 'eval_config': {'model_name': 'gemma-2-2b', 'random_seed': 42, 'f1_jump_threshold': 0.03, 'max_k_value': 10, 'prompt_template': '{word} has the first letter:', 'prompt_token_pos': -6, 'llm_batch_size': 32, 'llm_dtype': 'bfloat16', 'k_sparse_probe_l1_decay': 0.01, 'k_sparse_probe_batch_size': 4096, 'k_sparse_probe_num_epochs': 50}, 'sae_class': '', 'd_sae': 8000, 'train_tokens': 1e-06, 'l0': 19.99997329711914, 'frac_recovered': 0.039473684210526314}, 'gemma-2-2b_layer_5_additivity_trainer_3_custom_sae': {'mean_absorption_score': 0.27855316222744153, 'mean_num_split_features': 2.769230769230769, 'eval_config': {'model_name': 'gemma-2-2b', 'random_seed': 42, 'f1_jump_threshold': 0.03, 'max_k_value': 10, 'prompt_template': '{word} has the first letter:', 'prompt_token_pos': -6, 'llm_batch_size': 32, 'llm_dtype': 'bfloat16', 'k_sparse_probe_l1_decay': 0.01, 'k_sparse_probe_batch_size': 4096, 'k_sparse_probe_num_epochs': 50}, 'sae_class': '', 'd_sae': 8000, 'train_tokens': 1e-06, 'l0': 19.999988555908203, 'frac_recovered': 0.09868421052631579}}\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'scatter' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m image_base_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsorption\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mgraphing_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphing_sae_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcore_results_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_base_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer_markers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SAEBench/sae_bench_utils/graphing_utils.py:93\u001b[0m, in \u001b[0;36mplot_results\u001b[0;34m(selected_saes, results_path, core_results_path, image_base_name, k, trainer_markers, title_prefix)\u001b[0m\n\u001b[1;32m     90\u001b[0m title_3var \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mL0 vs Loss Recovered vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcustom_metric_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m title_2var \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mL0 vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcustom_metric_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 93\u001b[0m \u001b[43mplot_3var_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle_3var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolorbar_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCustom Metric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimage_base_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_3var.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer_markers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_markers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m plot_2var_graph(\n\u001b[1;32m    102\u001b[0m     eval_results,\n\u001b[1;32m    103\u001b[0m     custom_metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     trainer_markers\u001b[38;5;241m=\u001b[39mtrainer_markers,\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m plot_2var_graph_dict_size(\n\u001b[1;32m    111\u001b[0m     eval_results,\n\u001b[1;32m    112\u001b[0m     custom_metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     output_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_2var_dict_size.png\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m )\n",
      "File \u001b[0;32m~/SAEBench/sae_bench_utils/graphing_utils.py:401\u001b[0m, in \u001b[0;36mplot_3var_graph\u001b[0;34m(results, title, custom_metric, xlims, ylims, colorbar_label, output_filename, legend_location, x_axis_key, y_axis_key, trainer_markers)\u001b[0m\n\u001b[1;32m    398\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(trainer_label)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# Add colorbar\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m cbar \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[43mscatter\u001b[49m, ax\u001b[38;5;241m=\u001b[39max, label\u001b[38;5;241m=\u001b[39mcolorbar_label)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# Set labels and title\u001b[39;00m\n\u001b[1;32m    404\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL0 (Sparsity)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'scatter' where it is not associated with a value"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAISCAYAAABI07ejAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9TklEQVR4nO3df5TWdZ03/ufwa4ABZgA1U37kShNotWuARegaJrTlElqdrL1JMTPN8viD/AHtV+0Hi8S6LWfz1lzI0rsj3veuoYiuKTcqoNwIsWqFP1cN7ZSRwCA/BoHr+4eH68AyA1wXMPPBHo9z5pz38Hl/3q/3B98O87w+n+t91ZRKpVIAAABoVx3aewIAAAAIZwAAAIUgnAEAABSAcAYAAFAAwhkAAEABCGcAAAAFIJwBAAAUgHAGAABQAMIZAABAAQhnAAAABVBVOHv99ddz77335pprrsknP/nJHHbYYampqUlNTU0mTJhwgKf4tjvuuCNjxozJkUcema5du2bgwIEZP358Hn/88YNSDwAAoC3VlEqlUsUn1dS0euycc87JT37yk/2Z0y42bdqUz33uc7nvvvtaPN6hQ4dcc801ufbaaw9YTQAAgLa23481DhgwIGPGjDkQc2nRl7/85XIwGzVqVObMmZOlS5dm1qxZOfbYY7N9+/Zcd911ueWWWw7aHAAAAA62qu6cXXvttRk+fHiGDx+ed73rXXn55ZdzzDHHJDmwd87+7//9v/n4xz+eJBk7dmx+/vOfp2PHjuXjq1evztChQ/Pb3/42DQ0N+a//+q/07t37gNQGAABoS1XdOfv2t7+dv/3bv8273vWuAz2fXfzjP/5jkqRTp075n//zf+4SzJLksMMOy7Rp05Ika9euzcyZMw/qfAAAAA6Wwu7WuH79+syfPz9Jctppp6Vfv34t9vvMZz6TXr16JUl+/vOft9n8AAAADqTChrMnnngiW7ZsSZKccsoprfbr0qVLPvKRj5TPeeutt9pkfgAAAAdSYcPZb37zm3J78ODBe+y74/jWrVvz/PPPH9R5AQAAHAyd2nsCrXn11VfL7dYeadyhf//+5faqVaty3HHHtdivubk5zc3N5e+3b9+eN954I3379t3jxwMAAADvbKVSKevXr89RRx2VDh3a5x5WYcPZ+vXry+0ePXrssW9dXV25/eabb7bab+rUqfn2t7+9/5MDAADekVatWrXXm0MHS2HD2ebNm8vtLl267LFvbW1tub1p06ZW+02aNCmXX355+ft169ZlwIABWbVqVXlTEQAA4M9PU1NT+vfvn549e7bbHAobzrp27Vpu79gYpDU7P6rYrVu3VvvV1tbuEuR26NWrl3AGAAC069udCrshyM6JdU+PKibJhg0byu29PQIJAABQRIUNZzs/57nz5iAtWbVqVbm98+YgAAAAh4rChrOdd1x85pln9th3x/FOnTrlve9970GdFwAAwMFQ2HA2fPjw8kYgjzzySKv9tmzZkiVLlpTP6dy5c5vMDwAA4EAqbDjr2bNnPv7xjydJHnrooVYfbbzrrrvS1NSUJDnzzDPbbH4AAAAHUruFs5/85CepqalJTU1Nrrvuuhb7fPOb30ySbN26NV//+tezbdu2XY6vXr06V111VZKkoaEhX/nKVw7qnAEAAA6WqrbSX7RoUV544YXy96tXry63X3jhhfzkJz/Zpf+ECROqmtypp56aL3zhC5k9e3buueeejB49OpdeemmOOuqoPP3005kyZUp++9vfJkmmTZuW3r17V1UHAACgvVUVzmbOnJmf/vSnLR5bvHhxFi9evMufVRvOkuTHP/5xmpqact9992XBggVZsGDBLsc7dOiQ/+//+//y1a9+teoaAAAA7a2w7znboVu3bpk3b15+9rOfZfTo0TniiCPSpUuX9O/fP3/3d3+XRYsWtfpYJAAAwKGiplQqldp7Eu2lqakp9fX1WbduXXr16tXe0wEAANpJEbJB4e+cAQAA/DkQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACmC/w9krr7ySiRMnZvDgwamrq0ufPn0yfPjwTJ8+PRs3bjwQc8zLL7+cq666KkOHDk1DQ0M6d+6cPn365KMf/Wi+853v5PXXXz8gdQAAANpLTalUKlV78ty5czN+/Pg0NTW1eLyxsTHz5s3LoEGDqp7g7bffngsuuCCbNm1qtU+fPn0ye/bsjB49uqKxm5qaUl9fn3Xr1qVXr15VzxEAADi0FSEbVH3nbMWKFTnrrLPS1NSUHj16ZMqUKXnssccyf/78nH/++UmS5557LqeffnrWr19fVY3FixdnwoQJ2bRpUzp06JBzzz03c+bMydKlS/Nv//ZvGTt2bJLkjTfeyLhx4/Jf//Vf1V4OAABAu6r6ztlf//VfZ+HChenUqVMeffTRjBgxYpfj06dPz5VXXpkkufbaa3PddddVXONv//ZvM2/evCTJjTfemIsuumi3PhMnTsw//dM/JUm+/vWv54c//OE+j1+EdAwAALS/ImSDqsLZ0qVL8+EPfzhJcsEFF+Tmm2/erc/27dvz/ve/PytXrkxDQ0Nef/31dO7cuaI6ffr0yZo1a9K3b9+sXr26xT7r1q1LQ0NDkuRDH/pQli9fvs/jF+E/AAAA0P6KkA2qeqxxzpw55fa5557b8sAdOuTss89OkqxduzYLFiyouM6WLVuSJMccc0yrferr63PYYYft0h8AAOBQU1U4W7RoUZKkrq4uQ4cObbXfKaecUm4vXry44jrve9/7kiQvvfRSq32amprKd9V29AcAADjUVBXOVq5cmSQZNGhQOnXq1Gq/wYMH73ZOJS688MIkyZ/+9KcWH51Mku9+97u79QcAADjUtJ6sWrF58+bynap+/frtsW/v3r1TV1eXDRs2ZNWqVRVP7stf/nIWLVqU2267LV//+tezfPnyfPrTn8673/3u/Pa3v83tt99efsTyW9/6Vk477bSKawAAABRBxeFs523xe/Tosdf+O8LZm2++WWmpdOzYMT/96U8zduzY/MM//ENmzpyZmTNn7tJn1KhRmTx58j4Fs+bm5jQ3N5e/b+3z2QAAANpaxY81bt68udzu0qXLXvvX1tYmyR4/RHpPVq5cmdtuuy1PP/10i8cff/zxzJo1K6+99tpex5o6dWrq6+vLX/37969qTgAAAAdaxeGsa9eu5fa+7I64405Vt27dKi2VhQsXZsSIEZk7d26OPvro3H777fn973+fLVu2ZNWqVbnxxhvTvXv3zJ49OyeeeGJ+/etf73G8SZMmZd26deWvah61BAAAOBgqfqyxZ8+e5fa+PKq4YcOGJPv2COTOmpub88UvfjHr1q3LkUcemSVLluTII48sH+/Xr18uuuiinHLKKRk2bFh+97vf5ZxzzsmyZctaHbO2trZ8Jw8AAKBIqrpz1rdv3yTJq6++use+a9asKYezSh8h/I//+I/yo4oXX3zxLsFsZ8cff3zGjx+fJFm+fHmefPLJiuoAAAAUQVVb6R933HFJkhdeeCFbt25ttd8zzzxTbg8ZMqSiGjtvvf+hD31oj313/qy1nWsCAAAcKqoKZyeddFKStx9ZXL58eav9HnnkkXJ75MiRFdXY+fPT9hQAk+Stt95q8TwAAIBDRVXh7Iwzzii3b7311hb7bN++PbfddluSpKGhIaNGjaqoxjHHHFNuL1y4cI99dw6BO58HAABwqKgqnJ144ok5+eSTkySzZs3K448/vlufG264ofxo4iWXXJLOnTvvcvzhhx9OTU1NampqMmHChN3O//jHP57u3bsnSW666aZWt9K///778/Of/zxJcvTRR+ev/uqvqrkkAACAdlVVOEuSGTNmpFu3btm6dWvGjBmTqVOnZsmSJVmwYEEuuOCCXHnllUmSxsbGTJw4seLxGxoacvXVVyd5+4OvP/rRj2by5MlZsGBB/vM//zMPPPBALrroonz605/O9u3bkyTXX399OnSo+pIAAADaTdVv0DrhhBNy5513Zvz48WlqasrkyZN369PY2Jh58+btsv1+Jf7+7/8+b7zxRmbMmJE333wzU6dOzdSpU3fr17lz5/zDP/xDeddGAACAQ81+3WYaO3ZsnnrqqVx22WVpbGxM9+7d09DQkGHDhmXatGlZsWJFBg0aVPX4NTU1+cEPfpAnnngiF154Yd7//venZ8+e6dixY+rr6zN06NBcfvnl+dWvfpVvfvOb+3MpAAAA7aqmVCqV2nsS7aWpqSn19fVZt25devXq1d7TAQAA2kkRsoE3aAEAABSAcAYAAFAAwhkAAEABCGcAAAAFIJwBAAAUgHAGAABQAMIZAABAAQhnAAAABSCcAQAAFIBwBgAAUADCGQAAQAEIZwAAAAUgnAEAABSAcAYAAFAAwhkAAEABCGcAAAAFIJwBAAAUgHAGAABQAMIZAABAAQhnAAAABSCcAQAAFIBwBgAAUADCGQAAQAEIZwAAAAUgnAEAABSAcAYAAFAAwhkAAEABCGcAAAAFIJwBAAAUgHAGAABQAMIZAABAAQhnAAAABSCcAQAAFIBwBgAAUADCGQAAQAEIZwAAAAUgnAEAABSAcAYAAFAAwhkAAEABCGcAAAAFIJwBAAAUgHAGAABQAMIZAABAAQhnAAAABSCcAQAAFIBwBgAAUADCGQAAQAEIZwAAAAUgnAEAABSAcAYAAFAAwhkAAEABCGcAAAAFIJwBAAAUgHAGAABQAMIZAABAAQhnAAAABSCcAQAAFIBwBgAAUADCGQAAQAEIZwAAAAUgnAEAABSAcAYAAFAAwhkAAEABCGcAAAAFIJwBAAAUgHAGAABQAMIZAABAAQhnAAAABSCcAQAAFIBwBgAAUADCGQAAQAHsdzh75ZVXMnHixAwePDh1dXXp06dPhg8fnunTp2fjxo0HYo5lDz30UCZMmJBBgwalrq4u9fX1aWxszOc+97ncdNNNefPNNw9oPQAAgLZSUyqVStWePHfu3IwfPz5NTU0tHm9sbMy8efMyaNCgqieYJGvWrMm5556bu+++e4/9VqxYkb/6q7/a53GbmppSX1+fdevWpVevXvs1RwAA4NBVhGzQqdoTV6xYkbPOOiubNm1Kjx49MmnSpIwaNSqbNm3K7Nmz86//+q957rnncvrpp2fZsmXp2bNnVXXWrVuX0aNHZ/ny5UmSM888M5/73Ody7LHHpmPHjlm1alUeeeSR/Pu//3u1lwIAANDuqr5z9td//ddZuHBhOnXqlEcffTQjRozY5fj06dNz5ZVXJkmuvfbaXHfddVVN8Oyzz87tt9+e2tra/O///b/z6U9/usV+pVIp27ZtS6dO+543i5COAQCA9leEbFDVe86WLl2ahQsXJknOO++83YJZkkycODFDhgxJksyYMSNvvfVWxXUWLVqU22+/PUnyve99r9VgliQ1NTUVBTMAAIAiqSqczZkzp9w+99xzWx64Q4ecffbZSZK1a9dmwYIFFdf54Q9/mCSpr6/PN77xjconCgAAcIioKpwtWrQoSVJXV5ehQ4e22u+UU04ptxcvXlxRjS1btpQ3ABk9enS6du2aJNm2bVtWrVqVl19+OZs3b6506gAAAIVUVThbuXJlkmTQoEF7fJRw8ODBu52zr5588sly+PrABz6QpqamXHrppTnssMMyYMCAHHPMMamvr8/o0aPz8MMPV34RAAAABVJxONu8eXNWr16dJOnXr98e+/bu3Tt1dXVJklWrVlVU5ze/+U25vX379gwbNiwzZszI2rVry3++ZcuWPPTQQzn11FMzbdq0vY7Z3NycpqamXb4AAACKoOJwtn79+nK7R48ee+2/I5xV+gHRb7zxRrk9bdq0PP/88/mbv/mbLF26NJs3b87rr7+em266KfX19SmVSrn66qv3+jloU6dOTX19ffmrf//+Fc0JAADgYKnqztkOXbp02Wv/2traJMmmTZsqqrNhw4Zdao4ePTr33ntvhg8fntra2hx++OG58MILc++996ZDh7cvY9KkSdnTJwNMmjQp69atK39VejcPAADgYKk4nO3YmCN5+7HCvWlubk6SdOvWreo6ydt3zzp27Lhbv5NOOimf+cxnkrz9vrann3661TFra2vTq1evXb4AAACKoOJw1rNnz3J7Xx5V3HEHbF8egWytzuGHH54TTjih1b6f+MQnyu0nnniiojoAAABFUNWds759+yZJXn311T32XbNmTTmcVfr+rp37723jkZ37/vGPf6yoDgAAQBFUtZX+cccdlyR54YUXsnXr1lb7PfPMM+X2kCFDKqpx/PHHl9vbtm3bY9+dj+9pa38AAICiqiqcnXTSSUnefmRx+fLlrfZ75JFHyu2RI0dWVGPgwIEZMGBAkuTll1/e40YfL774Yrl99NFHV1QHAACgCKoKZ2eccUa5feutt7bYZ/v27bntttuSJA0NDRk1alTFdT772c8mSZqamjJ//vxW+911113l9o7gCAAAcCipKpydeOKJOfnkk5Mks2bNyuOPP75bnxtuuCErV65MklxyySXp3LnzLscffvjh1NTUpKamJhMmTGixzqWXXlretfHyyy9v8UOj/9f/+l95+OGHkySnn366zy4DAAAOSVWFsySZMWNGunXrlq1bt2bMmDGZOnVqlixZkgULFuSCCy7IlVdemSRpbGzMxIkTq6oxYMCAfOc730mSPP300znxxBNz6623Zvny5VmwYEEuvvjicrDr1atXfvCDH1R7OQAAAO2q6t0zTjjhhNx5550ZP358mpqaMnny5N36NDY2Zt68ebtsi1+pK664Im+88UamTZuWZ599Nl/+8pd363PEEUdkzpw5ee9731t1HQAAgPZU9Z2zJBk7dmyeeuqpXHbZZWlsbEz37t3T0NCQYcOGZdq0aVmxYkUGDRq035OcOnVqFi9enC996Ut5z3vek9ra2tTX12f48OH57ne/m+eeey4jRozY7zoAAADtpaa0p20Q3+GamppSX1+fdevWpVevXu09HQAAoJ0UIRvs150zAAAADgzhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAPY7nL3yyiuZOHFiBg8enLq6uvTp0yfDhw/P9OnTs3HjxgMxx91s3Lgxf/EXf5GamprU1NTkPe95z0GpAwAA0FY67c/Jc+fOzfjx49PU1FT+s40bN2bZsmVZtmxZZs6cmXnz5mXQoEH7PdGdXXPNNXnppZcO6JgAAADtqeo7ZytWrMhZZ52Vpqam9OjRI1OmTMljjz2W+fPn5/zzz0+SPPfcczn99NOzfv36AzbhFStW5J//+Z/TtWvX9OzZ84CNCwAA0J6qDmeXXHJJNm3alE6dOuUXv/hFJk+enBEjRuTUU0/NLbfcku9///tJ3g5oN9xwwwGZ7LZt23L++edn27ZtmTx5cvr06XNAxgUAAGhvVYWzpUuXZuHChUmS8847LyNGjNitz8SJEzNkyJAkyYwZM/LWW2/txzRTHmf58uV53/vel6uuumq/xwMAACiKqsLZnDlzyu1zzz235YE7dMjZZ5+dJFm7dm0WLFhQTamyV155Jddcc02S5Oabb06XLl32azwAAIAiqSqcLVq0KElSV1eXoUOHttrvlFNOKbcXL15cTamyiy66KBs2bMiXvvSlfOxjH9uvsQAAAIqmqnC2cuXKJMmgQYPSqVPrGz4OHjx4t3OqMXv27Nx3333p3bv3AXv/GgAAQJFUvJX+5s2bs3r16iRJv3799ti3d+/eqaury4YNG7Jq1aqqJrhmzZpceumlSZLrr78+hx9+eFXjJElzc3Oam5vL3+/8EQAAAADtqeI7Zztvi9+jR4+99q+rq0uSvPnmm5WWSpJcccUV+cMf/pARI0aUt+iv1tSpU1NfX1/+6t+//36NBwAAcKBUHM42b95cbu/Lphy1tbVJkk2bNlVaKo8++mh+/OMfp1OnTrn55ptTU1NT8Rg7mzRpUtatW1f+qvZuHgAAwIFW8WONXbt2Lbe3bNmy1/47HiPs1q1bRXWam5vz1a9+NaVSKZdcckk++MEPVjbRFtTW1pbDIgAAQJFUfOesZ8+e5fa+PKq4YcOGJPv2COTOpkyZkmeffTb9+/fPt7/97comCQAAcIip6s5Z375986c//SmvvvrqHvuuWbOmHM4qfX/XtGnTkiSnnXZa5s6d22KfHWNv2LAhs2fPTpIcccQROfXUUyuqBQAA0N4qDmdJctxxx2XhwoV54YUXsnXr1la303/mmWfK7SFDhlRUY8cjk7feemtuvfXWPfZdvXp1vvjFLyZ5+7PVhDMAAOBQU9XnnJ100klJ3r5jtXz58lb7PfLII+X2yJEjqykFAADwZ6GqcHbGGWeU263d1dq+fXtuu+22JElDQ0NGjRpVUY1SqbTXr4EDByZJBg4cWP6zhx9+uJpLAgAAaFdVhbMTTzwxJ598cpJk1qxZefzxx3frc8MNN2TlypVJkksuuSSdO3fe5fjDDz+cmpqa1NTUZMKECdVMAwAA4B2jqvecJcmMGTMycuTIbNq0KWPGjMnkyZMzatSobNq0KbNnz84tt9ySJGlsbMzEiRMP2IQBAADeiaoOZyeccELuvPPOjB8/Pk1NTZk8efJufRobGzNv3rxdtt8HAABgd1U91rjD2LFj89RTT+Wyyy5LY2NjunfvnoaGhgwbNizTpk3LihUrMmjQoAM1VwAAgHesmlKpVGrvSbSXpqam1NfXZ926denVq1d7TwcAAGgnRcgG+3XnDAAAgANDOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoAD2O5y98sormThxYgYPHpy6urr06dMnw4cPz/Tp07Nx48b9Gnvjxo2566678rWvfS3Dhw9P796907lz5/Tt2zcjRozIddddl9///vf7ewkAAADtrqZUKpWqPXnu3LkZP358mpqaWjze2NiYefPmZdCgQRWP/dRTT2XkyJF5880399ivV69eueWWW3LWWWdVXKOpqSn19fVZt25devXqVfH5AADAO0MRskHVd85WrFiRs846K01NTenRo0emTJmSxx57LPPnz8/555+fJHnuuedy+umnZ/369RWP39TUVA5mI0eOzNSpU/Pggw/ml7/8ZR544IFccMEF6dChQ5qamvI//sf/yP3331/tpQAAALS7TtWeeMkll2TTpk3p1KlTfvGLX2TEiBHlY6eeemre+9735sorr8xzzz2XG264Idddd11F43fo0CGf//znc+211+a4447b7fiYMWPyyU9+MmeeeWa2bduWiy++OM8//3xqamqqvSQAAIB2U9VjjUuXLs2HP/zhJMkFF1yQm2++ebc+27dvz/vf//6sXLkyDQ0Nef3119O5c+f9n/F/87nPfS7//u//niRZvnx5PvShD+3zuUW4dQkAALS/ImSDqh5rnDNnTrl97rnntjxwhw45++yzkyRr167NggULqim1V6NGjSq3X3zxxYNSAwAA4GCrKpwtWrQoSVJXV5ehQ4e22u+UU04ptxcvXlxNqb1qbm4utzt27HhQagAAABxsVYWzlStXJkkGDRqUTp1af9va4MGDdzvnQHvkkUfK7SFDhhyUGgAAAAdbxRuCbN68OatXr06S9OvXb499e/funbq6umzYsCGrVq2qboZ78OSTT2bevHlJkg984AN7DWfNzc273Glr7SMAAAAA2lrFd8523ha/R48ee+1fV1eXJHv9vLJKNTc35ytf+Uq2bduWJJkyZcpez5k6dWrq6+vLX/379z+gcwIAAKhWxeFs8+bN5XaXLl322r+2tjZJsmnTpkpL7dE3vvGNLFu2LElyzjnnZOzYsXs9Z9KkSVm3bl3562DczQMAAKhGxY81du3atdzesmXLXvvveIywW7dulZZq1dSpUzNz5swkyfDhw3PjjTfu03m1tbXlsAgAAFAkFd8569mzZ7m9L48qbtiwIcm+PQK5L370ox9l8uTJSd7ecOS+++4rPzoJAABwqKo4nHXt2jV9+/ZNkrz66qt77LtmzZpyODsQ7++64447ctFFFyVJBg4cmAcffDCHHXbYfo8LAADQ3qraSv+4445LkrzwwgvZunVrq/2eeeaZcnt/t7m/5557cvbZZ2f79u1597vfnfnz5+91t0gAAIBDRVXh7KSTTkry9iOLy5cvb7Xfzp9BNnLkyGpKJUnmz5+fz3/+89m6dWv69u2bBx98MMcee2zV4wEAABRNVeHsjDPOKLdvvfXWFvts3749t912W5KkoaEho0aNqqZUHnvssYwbNy7Nzc2pr6/PAw88kOOPP76qsQAAAIqqqnB24okn5uSTT06SzJo1K48//vhufW644YasXLkySXLJJZekc+fOuxx/+OGHU1NTk5qamkyYMKHFOv/5n/+Z008/PRs2bEhdXV3mzZuXoUOHVjNlAACAQqt4K/0dZsyYkZEjR2bTpk0ZM2ZMJk+enFGjRmXTpk2ZPXt2brnlliRJY2NjJk6cWPH4L774Yj7xiU9k7dq1SZLvfe97qa+vz69+9atWzzniiCNyxBFHVHU9AAAA7anqcHbCCSfkzjvvzPjx49PU1FTe3n5njY2NmTdv3i7b7++rhQsX5vXXXy9/f9lll+31nGuvvTbXXXddxbUAAADaW1WPNe4wduzYPPXUU7nsssvS2NiY7t27p6GhIcOGDcu0adOyYsWKDBo06EDNFQAA4B2rplQqldp7Eu2lqakp9fX1WbduXXr16tXe0wEAANpJEbLBft05AwAA4MAQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACmC/w9krr7ySiRMnZvDgwamrq0ufPn0yfPjwTJ8+PRs3bjwQc0yS3H///TnzzDPTr1+/1NbWpl+/fjnzzDNz//33H7AaAAAA7aWmVCqVqj157ty5GT9+fJqamlo83tjYmHnz5mXQoEFVT3D79u356le/mlmzZrXa5ytf+Up+9KMfpUOHyrJmU1NT6uvrs27duvTq1avqOQIAAIe2ImSDqu+crVixImeddVaamprSo0ePTJkyJY899ljmz5+f888/P0ny3HPP5fTTT8/69eurnuC3vvWtcjA74YQTcscdd2Tp0qW54447csIJJyRJZs6cmb//+7+vugYAAEB7q/rO2V//9V9n4cKF6dSpUx599NGMGDFil+PTp0/PlVdemSS59tprc91111Vc47nnnsvxxx+frVu3ZtiwYXn00UfTrVu38vGNGzfmlFNOybJly9KpU6esXLmyort0RUjHAABA+ytCNqjqztnSpUuzcOHCJMl55523WzBLkokTJ2bIkCFJkhkzZuStt96quM4///M/Z+vWrUmSf/mXf9klmCVJ9+7d8y//8i9Jkq1bt+YHP/hBxTUAAACKoKpwNmfOnHL73HPPbXngDh1y9tlnJ0nWrl2bBQsWVFSjVCrl7rvvTpIMHjw4H/nIR1rs95GPfCTve9/7kiR333139uMtdAAAAO2mqnC2aNGiJEldXV2GDh3aar9TTjml3F68eHFFNV566aX87ne/222cPdV57bXX8vLLL1dUBwAAoAiqCmcrV65MkgwaNCidOnVqtd/gwYN3O2df/eY3v2lxnANdBwAAoAhaT1at2Lx5c1avXp0k6dev3x779u7dO3V1ddmwYUNWrVpVUZ1XX3213N5bnf79+5fbe6rT3Nyc5ubm8vfr1q1LklY/CgAAAPjzsCMTtOfbpCoOZztvi9+jR4+99t8Rzt58882DVqeurq7c3lOdqVOn5tvf/vZuf75zuAMAAP58/elPf0p9fX271K7qztkOXbp02Wv/2traJMmmTZsOWp0dNfZWZ9KkSbn88svL369duzYDBw7Mb3/723b7D8Cfh6ampvTv3z+rVq3ysQ0cVNYabcVao61Ya7SVdevWZcCAAenTp0+7zaHicNa1a9dye8uWLXvtv+Mxwv++Df6BrLPzo4p7qlNbW7tLkNuhvr7e/+y0iV69ellrtAlrjbZirdFWrDXaSocOVW3LcWBqV3pCz549y+19eVRxw4YNSfbtEchq6+yoUU0dAACAIqg4nHXt2jV9+/ZNsuumHS1Zs2ZNOThV+r6unTcB2VudnTcB8f4xAADgUFTVPbvjjjsuSfLCCy9k69atrfZ75plnyu0hQ4ZUVeO/j3Mg69TW1ubaa69t8VFHOJCsNdqKtUZbsdZoK9YabaUIa62mVMVekZMnT87UqVOTJEuWLMmHP/zhFvtdf/31mTRpUpLkgQceyJgxY/a5RqlUSr9+/fK73/0ugwcP3uPnlw0ZMiTPPPNMjj766KxatSo1NTUVXA0AAED7q+rO2RlnnFFu33rrrS322b59e2677bYkSUNDQ0aNGlVRjZqamowbNy7J23fGlixZ0mK/JUuWlO+cjRs3TjADAAAOSVWFsxNPPDEnn3xykmTWrFl5/PHHd+tzww03lO92XXLJJencufMuxx9++OHU1NSkpqYmEyZMaLHOpZdemo4dOyZJLr744t22yd+0aVMuvvjiJEmnTp1y6aWXVnM5AAAA7a7qfSJnzJiRbt26ZevWrRkzZkymTp2aJUuWZMGCBbngggty5ZVXJkkaGxszceLEqmo0NjbmiiuuSJIsW7YsI0eOzJ133plly5blzjvvzMiRI7Ns2bIkyRVXXJH3vve91V4OAABAu6rqPWc7zJ07N+PHj09TU1OLxxsbGzNv3rwMGjRot2MPP/xw+VHHc845Jz/5yU9aHGP79u05//zz8+Mf/7jVeZx33nm55ZZb2vUzCQAAAPbHfqWZsWPH5qmnnspll12WxsbGdO/ePQ0NDRk2bFimTZuWFStWtBjMKppghw6ZNWtW5s2bl3HjxuWoo45Kly5dctRRR2XcuHG57777MnPmTMEMAAA4pO13ohk4cGD+6Z/+Kc8++2w2bNiQNWvW5IknnsiVV16Z7t27t3rexz72sZRKpZRKpVbvmu3sU5/6VObMmZPXXnstzc3Nee211zJnzpwcd9xxmThxYgYPHpy6urr06dMnw4cPz/Tp07Nx48b9vbyy+++/P2eeeWb69euX2tra9OvXL2eeeWbuv//+A1aDYnvllVcO2lrbuHFj7rrrrnzta1/L8OHD07t373Tu3Dl9+/bNiBEjct111+X3v//9AboSiu5grrXWbNy4MX/xF39Rfi/we97znoNSh2Jpy7X20EMPZcKECRk0aFDq6upSX1+fxsbGfO5zn8tNN92UN99884DWo1jaYq29/PLLueqqqzJ06NA0NDSkc+fO6dOnTz760Y/mO9/5Tl5//fUDUofief3113PvvffmmmuuySc/+ckcdthhe93bYn/dcccdGTNmTI488sh07do1AwcOzPjx41vci6MipUPYPffcU+rVq1cpSYtfjY2Npeeff36/amzbtq103nnntVojSekrX/lKadu2bQfoqiiig7nWnnzyyVKPHj32uMaSlHr16lWaPXv2Ab4yiqYtfq61ZOLEibvUGThw4AGvQbG01Vp74403SuPGjdvrz7gVK1bs/0VRSG2x1m677bZSt27d9rjG+vTpU/rFL35xgK6KItnTf/dzzjnngNbauHFj6VOf+lSr9Tp06FC67rrrqh7/kA1nv/zlL8v/E/bo0aM0ZcqU0mOPPVaaP39+6fzzz9/lf/impqaq61x99dXlsU444YTSHXfcUVq6dGnpjjvuKJ1wwgnlY5MmTTqAV0eRHOy1tnDhwvIYI0eOLE2dOrX04IMPln75y1+WHnjggdIFF1xQ6tChQylJqWPHjqX77rvvIFwlRdBWP9daqtuxY8dS165dSz179hTO/gy01Vpbu3ZtaejQoeXxzjzzzNLPfvaz0pIlS0pPPPFE6a677ipdcsklpX79+gln71BtsdYWLVpU/neyQ4cOpXPPPbc0Z86c0tKlS0v/9m//Vho7dmy5Trdu3UovvvjiAb5K2tvO4WjAgAGlMWPGHLRw9oUvfKE89qhRo8prbdasWaVjjz22fOxHP/pRdddyQGfbhk4++eRSklKnTp1Kjz322G7Hv//975f/cq699tqqajz77LOlTp06lZKUhg0bVtq4ceMuxzds2FAaNmxYeR4H49Vs2t/BXmuLFy8uff7zny/9+te/brXPnDlzSjU1NaUkpWOPPba0ffv2iutQfG3xc+2/27p1a/mX5+985zulgQMHCmd/BtpqrX3pS18qJSnV1taW7r777lb7bd++vfTWW29VXYfiaou1dvrpp5fHuPHGG1vsc/nll5f7fP3rX6+qDsV1zTXXlObOnVv6/e9/XyqVSqWXXnrpoISz+fPnl8cdO3ZsaevWrbsc/+Mf/1gaMGBAKUmpoaGh9MYbb1Rc45AMZ//v//2/8l/MBRdc0GKfbdu2lYYMGVL+y9myZUvFdb72ta+V6zz++OMt9nn88cfLfS666KKKa1BsbbXW9sVnP/vZ8lyWL19+UGrQftprrd1www2lJKX3ve99pebmZuHsz0BbrbWdnwqYPn36/k6bQ1BbrbXevXuXkpT69u3bap+1a9eW5/KhD32o4hocWg5WOPvkJz9ZfrFh1apVLfa54447yrW///3vV1zjkNzicM6cOeX2ueee22KfDh065Oyzz06SrF27NgsWLKioRqlUyt13350kGTx4cD7ykY+02O8jH/lI3ve+9yVJ7r777pSq/2QCCqgt1tq+2vHRE0ny4osvHpQatJ/2WGuvvPJKrrnmmiTJzTffnC5duuzXeBwa2mqt/fCHP0yS1NfX5xvf+EblE+WQ11ZrbcuWLUmSY445ptU+9fX1Oeyww3bpD5VYv3595s+fnyQ57bTT0q9fvxb7feYzn0mvXr2SJD//+c8rrnNIhrNFixYlSerq6jJ06NBW+51yyinl9uLFiyuq8dJLL+V3v/vdbuPsqc5rr72Wl19+uaI6FFtbrLV91dzcXG537NjxoNSg/bTHWrvooouyYcOGfOlLX8rHPvax/RqLQ0dbrLUtW7aUX+AcPXp0unbtmiTZtm1bVq1alZdffjmbN2+udOocYtrq59qOF8lfeumlVvs0NTVl9erVu/SHSjzxxBPlYL+nbNClS5fyTZ0nnngib731VkV1DslwtnLlyiTJoEGD0qlTp1b7DR48eLdz9tVvfvObFsc50HUotrZYa/vqkUceKbeHDBlyUGrQftp6rc2ePTv33XdfevfunRtuuKHqcTj0tMVae/LJJ8vh6wMf+ECamppy6aWX5rDDDsuAAQNyzDHHpL6+PqNHj87DDz9c+UVwSGirn2sXXnhhkuRPf/pTbr755hb7fPe7392tP1SimmywdevWPP/88xXVOeTC2ebNm8uvfLR2O3GH3r17p66uLkmyatWqiuq8+uqr5fbe6vTv37/crrQOxdVWa21fPPnkk5k3b16St3/REc7eWdp6ra1ZsyaXXnppkuT666/P4YcfXtU4HHraaq3t/EvM9u3bM2zYsMyYMSNr164t//mWLVvy0EMP5dRTT820adMqGp/ia8ufa1/+8pfLj0Z+/etfz/nnn5+5c+dm2bJlueuuu3LmmWfmH//xH5Mk3/rWt3LaaadVXAPaKhsccuFs/fr15XaPHj322n/H/+yVfrhlJXV21KimDsXVVmttb5qbm/OVr3wl27ZtS5JMmTLlgI5P+2vrtXbFFVfkD3/4Q0aMGJHzzz+/qjE4NLXVWnvjjTfK7WnTpuX555/P3/zN32Tp0qXZvHlzXn/99dx0002pr69PqVTK1VdfXX4MkneGtvy51rFjx/z0pz/N//k//yd/+Zd/mZkzZ+bTn/50hg8fns9+9rOZM2dORo0alQcffDDf+973Kh4fkrbLBodcONv5GfV9efN6bW1tkmTTpk0Hrc6OGtXUobjaaq3tzTe+8Y0sW7YsSXLOOedk7NixB3R82l9brrVHH300P/7xj9OpU6fcfPPNqampqXgMDl1ttdY2bNiwS83Ro0fn3nvvzfDhw1NbW5vDDz88F154Ye6999506PD2ryKTJk2yqdY7SFv/G7py5crcdtttefrpp1s8/vjjj2fWrFl57bXXqhof2iobHHLhbMebipN9221nxyYK3bp1O2h1dt6oodI6FFdbrbU9mTp1ambOnJkkGT58eG688cYDNjbF0VZrrbm5OV/96ldTKpVyySWX5IMf/GBlE+WQ1x7/hiZv3z1raSOjk046KZ/5zGeSvP3LdWu/WHPoact/QxcuXJgRI0Zk7ty5Ofroo3P77bfn97//fbZs2ZJVq1blxhtvTPfu3TN79uyceOKJ+fWvf11xDWirbHDIhbOePXuW2/tym3DHq3f7cku92jo7v0JYaR2Kq63WWmt+9KMfZfLkyUnefmPpfffdt8ttct452mqtTZkyJc8++2z69++fb3/725VNkneE9vg39PDDD88JJ5zQat9PfOIT5fYTTzxRUR2Kq63WWnNzc774xS9m3bp1OfLII7NkyZKMHz8+73rXu9K5c+f069cvF110UR599NF07do1v/vd73LOOedUdjGQtssGrW+dU1Bdu3ZN375986c//WmXN+a1ZM2aNeW/nJ3fmLcvdn6j397q7PxGv0rrUFxttdZacscdd+Siiy5KkgwcODAPPvhg+fNZeOdpq7W2Y9OF0047LXPnzm2xz46xN2zYkNmzZydJjjjiiJx66qkV1aKY2mqt7dy/kjfO//GPf6yoDsXVVmvtP/7jP8qPKl588cU58sgjW+x3/PHHZ/z48Zk5c2aWL1+eJ598Mn/5l39ZUS3+vP33bDBs2LBW++5PNjjkwlmSHHfccVm4cGFeeOGFbN26tdXtWZ955plyu9Ld7Y477rgWxznQdSi2tlhr/90999yTs88+O9u3b8+73/3uzJ8/f6+/3HDoa4u1tuMxjFtvvTW33nrrHvuuXr06X/ziF5O8/Xkuwtk7R1usteOPP77c3rGZUWt2Pr6n7dY59LTFWtt56/0PfehDe+w7dOjQ8lsFnnnmGeGMilSTDTp16pT3vve9FdU55B5rTN5+Rj15+5Xd5cuXt9pv58+FGjlyZEU1jjnmmBx11FG7jdOSRx99NEly9NFH5z3veU9FdSi2tlhrO5s/f34+//nPZ+vWrenbt28efPDBHHvssVWPx6Gjrdcaf77aYq0NHDgwAwYMSJK8/PLLe9zo48UXXyy3jz766IrqUGxtsdZ2Dnxbt27dY9+dPwzYCwFUavjw4eWNQPaUDbZs2ZIlS5aUz+ncuXNFdQ7JcHbGGWeU2629+rt9+/bcdtttSZKGhoaMGjWqoho1NTUZN25ckrfT746/5P9uyZIl5XQ8btw4O5+9w7TFWtvhsccey7hx49Lc3Jz6+vo88MADu7z6zDtbW6y1Uqm016+BAwcmefuX6x1/5kOC31na6ufaZz/72SRJU1NT5s+f32q/u+66q9ze8cs87wxtsdaOOeaYcnvhwoV77LvzL9Q7nwf7omfPnvn4xz+eJHnooYdafVz3rrvuSlNTU5LkzDPPrLxQ6RB18sknl5KUOnXqVHrsscd2O/7973+/lKSUpHTttdfudnzBggXl4+ecc06LNZ599tlSx44dS0lKw4YNK23cuHGX4xs3biwNGzasPI/nnnvuQFwaBdMWa23FihWlhoaGUpJSXV1dadGiRQf4KjgUtMVa25uBAweWkpQGDhxY1fkcGtpirb3yyiulrl27lpKUPvCBD5TWrVu3W5/bb7+9PM7pp5++v5dFAR3stbZmzZpS9+7dS0lKPXv2LD311FMtzuO+++4rdejQoZSkdPTRR5e2bdu2v5dGgb300ksV/3t466237nEtlkql0vz588t9Pv3pT5e2bt26y/E//vGPpQEDBpSSlBoaGkpvvPFGxXM/ZO/pzpgxIyNHjsymTZsyZsyYTJ48OaNGjcqmTZsye/bs3HLLLUmSxsbGTJw4saoajY2NueKKK3L99ddn2bJlGTlyZK666qoce+yxefHFFzNt2rSsWLEiydsf6lrpM6UcGg72WnvxxRfziU98ImvXrk2SfO9730t9fX1+9atftXrOEUcckSOOOKKq66G42uLnGiRts9YGDBiQ73znO7nyyivz9NNP58QTT8xVV12VD37wg2lqaspdd92Vm266KUnSq1ev/OAHPzhg10dxHOy11tDQkKuvvjrXXHNN1q9fn49+9KO5+OKLM3r06PTu3Tt/+MMfcvfdd+df//Vfs3379iTJ9ddfX/58Pd4ZFi1alBdeeKH8/erVq8vtF154IT/5yU926T9hwoSq6px66qn5whe+kNmzZ+eee+7J6NGjc+mll+aoo47K008/nSlTpuS3v/1tkrc34erdu3flRSqOcwVyzz33lHr16lVOsP/9q7GxsfT888+3eO6+vsK8bdu20pe//OVWayQpnXfeeV6BeYc7mGtt51dq9vWrtVd0OPS1xc+1PXHn7M9HW621q6++ulRTU9NqnSOOOKLFOyq8cxzstbZ9+/bSpZdeusd1lqTUuXPn0vTp0w/ildJezjnnnIp+j2rJvtw5K5XefnLuU5/6VKtjd+jQYb9+TzukXzYYO3ZsnnrqqVx22WVpbGxM9+7d09DQkGHDhpXvag0aNGi/anTo0CGzZs3KvHnzMm7cuBx11FHp0qVLjjrqqIwbNy733XdfZs6c6RWYd7i2WGuQWGu0nbZaa1OnTs3ixYvzpS99Ke95z3tSW1ub+vr6DB8+PN/97nfz3HPPZcSIEQfgiiiqg73Wampq8oMf/CBPPPFELrzwwrz//e9Pz54907Fjx9TX12fo0KG5/PLL86tf/Srf/OY3D+CV8eeoW7dumTdvXn72s59l9OjROeKII9KlS5f0798/f/d3f5dFixbluuuuq3r8mlJpD1soAQAA0Cbc7gEAACgA4QwAAKAAhDMAAIACEM4AAAAKQDgDAAAoAOEMAACgAIQzAACAAhDOAAAACkA4AwAAKADhDAAAoACEMwAAgAIQzgAAAApAOAMAACgA4QwAAKAA/n+AHWh2saaoAQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_base_name = os.path.join(image_path, \"absorption\")\n",
    "\n",
    "graphing_utils.plot_results(graphing_sae_ids, eval_path, core_results_path, image_base_name, k, trainer_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ravel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
